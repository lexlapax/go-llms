# LLM Package

The `llm` package provides interfaces and implementations for interacting with Language Model providers such as OpenAI and Anthropic. It handles the communication with these services and provides a unified API across different providers.

## Core Components

### Domain

#### Message

```go
type Role string

const (
    RoleSystem    Role = "system"
    RoleUser      Role = "user"
    RoleAssistant Role = "assistant"
    RoleTool      Role = "tool"
)

type Message struct {
    Role    Role   `json:"role"`
    Content string `json:"content"`
}
```

The `Message` struct represents a message in a conversation with a language model, with different roles such as system, user, assistant, or tool.

#### Response

```go
type Response struct {
    Content string `json:"content"`
    // Additional fields like metadata may be available depending on the provider
}
```

The `Response` struct contains the content generated by the language model.

#### Token

```go
type Token struct {
    Text     string `json:"text"`
    Finished bool   `json:"finished"`
}
```

The `Token` struct represents a token in a streamed response from a language model, with a flag indicating whether it's the final token.

#### ResponseStream

```go
type ResponseStream <-chan Token
```

`ResponseStream` is a channel that receives tokens from a streaming response.

### Provider Interface

```go
type Provider interface {
    // Generate produces text from a prompt
    Generate(ctx context.Context, prompt string, options ...Option) (string, error)
    
    // GenerateMessage produces a response from a sequence of messages
    GenerateMessage(ctx context.Context, messages []Message, options ...Option) (Response, error)
    
    // GenerateWithSchema produces structured output conforming to a schema
    GenerateWithSchema(ctx context.Context, prompt string, schema interface{}, options ...Option) (interface{}, error)
    
    // Stream streams responses token by token
    Stream(ctx context.Context, prompt string, options ...Option) (ResponseStream, error)
    
    // StreamMessage streams a response from a sequence of messages
    StreamMessage(ctx context.Context, messages []Message, options ...Option) (ResponseStream, error)
}
```

The `Provider` interface defines methods for generating text and streaming responses from language models, with support for both simple prompts and message-based conversations.

### Provider Options

```go
type Option func(*ProviderOptions)

type ProviderOptions struct {
    Temperature      float64
    MaxTokens        int
    StopSequences    []string
    TopP             float64
    FrequencyPenalty float64
    PresencePenalty  float64
}

// WithTemperature sets the temperature for generation
func WithTemperature(temp float64) Option

// WithMaxTokens sets the maximum number of tokens to generate
func WithMaxTokens(max int) Option

// WithStopSequences sets sequences that stop generation
func WithStopSequences(sequences ...string) Option

// WithTopP sets the top-p value for nucleus sampling
func WithTopP(topP float64) Option

// WithFrequencyPenalty sets the frequency penalty
func WithFrequencyPenalty(penalty float64) Option

// WithPresencePenalty sets the presence penalty
func WithPresencePenalty(penalty float64) Option
```

These options configure the behavior of the language model, such as the randomness of outputs, length limits, and more.

## Provider Implementations

### OpenAI Provider

```go
// Create a new OpenAI provider
provider := provider.NewOpenAIProvider(
    "your-api-key",
    "gpt-4o", // Model name
)

// Generate text
response, err := provider.Generate(ctx, "What is the capital of France?")

// Generate with options
response, err := provider.Generate(
    ctx,
    "Write a poem about programming.",
    domain.WithTemperature(0.7),
    domain.WithMaxTokens(200),
)

// Stream response
stream, err := provider.Stream(ctx, "Tell me a story.")
if err != nil {
    // Handle error
}

for token := range stream {
    fmt.Print(token.Text)
    if token.Finished {
        fmt.Println()
    }
}
```

The OpenAI provider supports all OpenAI models including GPT-3.5, GPT-4, and GPT-4o.

### Anthropic Provider

```go
// Create a new Anthropic provider
provider := provider.NewAnthropicProvider(
    "your-api-key",
    "claude-3-5-sonnet-latest", // Model name
)

// Message-based conversation
messages := []domain.Message{
    {Role: domain.RoleSystem, Content: "You are a helpful assistant."},
    {Role: domain.RoleUser, Content: "What is the meaning of life?"},
}

response, err := provider.GenerateMessage(ctx, messages)
```

The Anthropic provider supports Claude models including Claude 3 Opus, Sonnet, and Haiku.

### Mock Provider

```go
// Create a mock provider with default responses
provider := provider.NewMockProvider()

// Customize the mock provider's behavior
provider.WithGenerateFunc(func(ctx context.Context, prompt string, options ...domain.Option) (string, error) {
    return "This is a custom mock response for: " + prompt, nil
})
```

The mock provider is useful for testing and development without making actual API calls.

## Multi Provider

The multi provider allows using multiple LLM providers together with different strategies:

```go
// Create provider weights
providers := []provider.ProviderWeight{
    {Provider: openAIProvider, Weight: 1.0, Name: "openai"},
    {Provider: anthropicProvider, Weight: 1.0, Name: "anthropic"},
}

// Create a multi-provider with the fastest strategy
fastestProvider := provider.NewMultiProvider(providers, provider.StrategyFastest)

// Create a multi-provider with the primary strategy
primaryProvider := provider.NewMultiProvider(providers, provider.StrategyPrimary).
    WithPrimaryProvider(0) // Use first provider as primary

// Create a multi-provider with the consensus strategy
consensusProvider := provider.NewMultiProvider(providers, provider.StrategyConsensus)
```

Multi-provider strategies include:

- **StrategyFastest**: Returns the result from the provider that responds first
- **StrategyPrimary**: Uses a designated primary provider, falling back to others on failure
- **StrategyConsensus**: Attempts to find consensus among multiple providers' results

### Consensus Configuration

```go
// Create a multi-provider with custom consensus configuration
consensusProvider := provider.NewMultiProvider(providers, provider.StrategyConsensus).
    WithConsensusStrategy(provider.ConsensusSimilarity). // Use similarity-based consensus
    WithSimilarityThreshold(0.7) // Set similarity threshold to 70%
```

Consensus strategies include:

- **ConsensusMajority**: Uses simple majority voting (most common response)
- **ConsensusSimilarity**: Groups responses by similarity and chooses largest group
- **ConsensusWeighted**: Considers provider weights in addition to response similarity

## Example Usage

### Simple Text Generation

```go
// Create a provider
provider := provider.NewOpenAIProvider("your-api-key", "gpt-4o")

// Generate text
response, err := provider.Generate(context.Background(), "What is the capital of France?")
if err != nil {
    fmt.Printf("Error: %v\n", err)
    return
}

fmt.Printf("Response: %s\n", response)
```

### Message-Based Conversation

```go
// Create a provider
provider := provider.NewAnthropicProvider("your-api-key", "claude-3-5-sonnet-latest")

// Define messages
messages := []domain.Message{
    {Role: domain.RoleSystem, Content: "You are a helpful assistant."},
    {Role: domain.RoleUser, Content: "What is the meaning of life?"},
}

// Generate response
response, err := provider.GenerateMessage(context.Background(), messages)
if err != nil {
    fmt.Printf("Error: %v\n", err)
    return
}

fmt.Printf("Response: %s\n", response.Content)
```

### Streaming Response

```go
// Create a provider
provider := provider.NewOpenAIProvider("your-api-key", "gpt-4o")

// Stream response
stream, err := provider.Stream(context.Background(), "Tell me a story about a dragon.")
if err != nil {
    fmt.Printf("Error: %v\n", err)
    return
}

fmt.Println("Streaming response:")
for token := range stream {
    fmt.Print(token.Text)
    if token.Finished {
        fmt.Println()
    }
}
```
